{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4b9f72",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis & Feature Engineering\n",
    "\n",
    "Objective:\n",
    "    1. To get an insight into input dataframe.\n",
    "    2. To get an understanding of basic statistics.\n",
    "    3. Identify features of importance through VIF, PCA and / or Decision Trees\n",
    "\n",
    "Assumptions:\n",
    "    1. Only *.csv files are currently being read.\n",
    "    2. Target columns are placed after the features in the *.csv\n",
    "    3. Median imputing is performed where needed. Change it appropriately as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac741f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:16.038315Z",
     "start_time": "2021-05-15T05:16:13.925572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.options.display.width=None\n",
    "\n",
    "import ppscore as pps\n",
    "\n",
    "from tabulate import tabulate\n",
    "tabulate.PRESERVE_WHITESPACE = False\n",
    "\n",
    "from pca import pca\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.decomposition import PCA as SKLPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dae38d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:16.053913Z",
     "start_time": "2021-05-15T05:16:16.038315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global constants\n",
    "\n",
    "RND_STATE = 39  # random_state where used is assigned RND_STATE\n",
    "TESTSIZE = 0.2  # test_size where used is assigned TESTSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35d829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:16.179514Z",
     "start_time": "2021-05-15T05:16:16.054850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset I/O definitions\n",
    "\n",
    "PATH = r\"C:\\DSML_Case_Studies\\01_Classification\\01_Dataset\"\n",
    "OUTPATH = r\"C:\\DSML_Case_Studies\\01_Classification\\03_Output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0abc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:36.475808Z",
     "start_time": "2021-05-15T05:16:16.180617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick the dataset to be analyzed & specify a prefix for output files and figures\n",
    "\n",
    "for r, d, f in os.walk(PATH):\n",
    "    for file in f:\n",
    "        if file.endswith(\".csv\"):\n",
    "            continue\n",
    "    print(f)\n",
    "nfiles = len(f)\n",
    "\n",
    "userinp = int(input(\"Enter input file index:\"))\n",
    "while userinp > (nfiles-1):\n",
    "    print(f)\n",
    "    userinp = int(input(\"Enter input file index:\"))\n",
    "    continue\n",
    "\n",
    "files = f[userinp]\n",
    "\n",
    "FNAME = f\"{PATH}\\{files}\"\n",
    "\n",
    "PREFIX = input(\"Prefix for Output Files & Figures: \")\n",
    "PREFIX = f\"\\{PREFIX}\"\n",
    "\n",
    "# Specify number of features and targets in the dataset\n",
    "\n",
    "n_features = int(input(\"Enter the Number of Features in Dataset: \"))\n",
    "n_target = int(input(\"Enter the Number of Targets in Dataset: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512421d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:36.539426Z",
     "start_time": "2021-05-15T05:16:36.476783Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset Definition\n",
    "\n",
    "df = pd.read_csv(f\"{FNAME}\")\n",
    "df = df.round(decimals=4)\n",
    "maxcol = len(df.columns)\n",
    "\n",
    "DF_INFO = df.dtypes.to_frame('Data Type').reset_index()\n",
    "\n",
    "collst = []\n",
    "for columns in df.columns:\n",
    "    collst.append(columns)\n",
    "\n",
    "featlst = collst[0:len(collst)-n_target]\n",
    "targlst = collst[-n_target:]\n",
    "\n",
    "pd.set_option('display.max_columns', len(collst))\n",
    "\n",
    "cat_df = df.select_dtypes(include=['object'])\n",
    "catlst = []\n",
    "for col in cat_df.columns:\n",
    "    catlst.append(col)\n",
    "\n",
    "y_catlst = [value for value in catlst if value in targlst]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5e121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:37.512323Z",
     "start_time": "2021-05-15T05:16:36.540427Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dataframe BEFORE Encoding: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310c471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:37.655747Z",
     "start_time": "2021-05-15T05:16:37.513322Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006e46c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:37.749483Z",
     "start_time": "2021-05-15T05:16:37.657742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Categorical Columns\n",
    "\n",
    "for i in range(0, len(collst), 1):\n",
    "    temp = df.dtypes[collst[i]]\n",
    "    if temp == 'object':\n",
    "        df[collst[i]] = df[collst[i]].astype('category')\n",
    "        df[collst[i]] = df[collst[i]].cat.codes\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723547a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:37.923050Z",
     "start_time": "2021-05-15T05:16:37.751477Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dataframe AFTER Encoding: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cf05a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.069057Z",
     "start_time": "2021-05-15T05:16:37.924048Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eab3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.179267Z",
     "start_time": "2021-05-15T05:16:38.070054Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dataframe BEFORE Imputing: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fcaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.303696Z",
     "start_time": "2021-05-15T05:16:38.180265Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681a348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.413300Z",
     "start_time": "2021-05-15T05:16:38.305694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Imputing\n",
    "\n",
    "''' Use Appropriate Imputer - Mean, Meadian, Mode... Others '''\n",
    "\n",
    "df = df.apply(lambda x: x.fillna(x.median()), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b63485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.524134Z",
     "start_time": "2021-05-15T05:16:38.414295Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dataframe AFTER MEDIAN Imputing: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862e919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.650850Z",
     "start_time": "2021-05-15T05:16:38.525835Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984c6a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.779423Z",
     "start_time": "2021-05-15T05:16:38.652274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity checks before proceeding further\n",
    "\n",
    "print(\"List of Features:\", featlst, end='\\n\\n')\n",
    "print(\"List of Targets:\", targlst, end='\\n\\n')\n",
    "print(\"List of Categorical Variables:\", catlst, end='\\n\\n')\n",
    "print(\"List of Categorical Targets\", y_catlst, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133e84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:38.905604Z",
     "start_time": "2021-05-15T05:16:38.780354Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Descriptive Stats: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6f298",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:39.036421Z",
     "start_time": "2021-05-15T05:16:38.906869Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc_stat = df.describe().T.round(3) # Univariate analyses\n",
    "print(tabulate(desc_stat, headers=desc_stat.columns, tablefmt=\"github\", numalign=\"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162109be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:43.917424Z",
     "start_time": "2021-05-15T05:16:39.038103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for Normality - Visual Check - Plots not being saved.\n",
    "\n",
    "for x in collst:\n",
    "    fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(15,5))\n",
    "    sns.histplot(data=df,x=x,kde=True,ax=ax[0])\n",
    "    sm.qqplot(df[x],ax=ax[1],line='45',fit=True)\n",
    "    ax[1].set_xlabel(x)\n",
    "    sns.boxplot(data=df,x=x,ax=ax[2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5ea3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:52.200562Z",
     "start_time": "2021-05-15T05:16:43.917424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Box Plot\n",
    "\n",
    "if len(y_catlst)!= 0:\n",
    "    NCOLS = 4\n",
    "    m_rows = int(np.ceil((len(collst)-len(y_catlst))/NCOLS))\n",
    "    fig, axes = plt.subplots(m_rows, NCOLS, figsize = (15,15))\n",
    "    axes = axes.flatten()\n",
    "    for lst in range(0, len(y_catlst), 1):\n",
    "        temp = 'Fig_0' + str(lst)\n",
    "        FIG1 = f\"{temp}_Boxplot\"\n",
    "        for i in range(0,len(df.columns)-len(y_catlst)):\n",
    "            sns.boxplot(x=y_catlst[lst], y=df.iloc[:,i], data=df, orient='v', ax=axes[i])\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{OUTPATH}{PREFIX}{FIG1}\")\n",
    "\n",
    "if len(y_catlst)== 0:\n",
    "    FIG1 = r\"Fig_01_Boxplot\"\n",
    "    lst = [x for x in collst if x not in y_catlst]\n",
    "    fig, axes = plt.subplots(1, len(lst), figsize = (45,15))\n",
    "    axes = axes\n",
    "    for i, col in enumerate(lst):\n",
    "        ax = sns.boxplot(y=df[col], ax=axes.flatten()[i])\n",
    "        axminlt = df[col].min()-0.1*df[col].min()\n",
    "        axmaxlt = df[col].max()+0.1*df[col].max()\n",
    "        ax.set_ylim(axminlt, axmaxlt)\n",
    "        ax.set_ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPATH}{PREFIX}{FIG1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a903f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:16:57.978362Z",
     "start_time": "2021-05-15T05:16:52.201559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Linear Correlation Heatmap\n",
    "\n",
    "cormethod = {0:'pearson', 1:'kendall', 2:'spearman'}\n",
    "for i in range(0, 3, 1):\n",
    "    temp = 'linear_cor' + str(i)\n",
    "    temp = df.corr(method=cormethod[i])\n",
    "    ftemp = cormethod[i].title()\n",
    "    FIG2 = r\"Fig_02_Corr_\"\n",
    "    mask = np.zeros(temp.shape, dtype=bool)\n",
    "    mask[np.triu_indices(len(mask))] = True\n",
    "    plt.subplots(figsize=(20,15))\n",
    "    plt.title(f\"{ftemp} Corrlelation\")\n",
    "    sns.heatmap(temp, annot=True, vmin=-1, vmax=1, center=0,\n",
    "                cmap='coolwarm', square=True, mask=mask, fmt='.2f')\n",
    "    plt.savefig(f\"{OUTPATH}{PREFIX}{FIG2}{ftemp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd28994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:04.171947Z",
     "start_time": "2021-05-15T05:16:57.979360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Non-Linear Correlation Predictive Power Score - Heatmap\n",
    "\n",
    "FIG3 = r\"Fig_03_Predictive_Power_Score\"\n",
    "\n",
    "ppscorr = pps.matrix(df) # Predictive Power Score - PPS\n",
    "matrix_df = pps.matrix(df)[['x', 'y', 'ppscore']].pivot(columns='x', index='y',\n",
    "                                                        values='ppscore')\n",
    "plt.subplots(figsize=(20,15))\n",
    "sns.heatmap(matrix_df, cmap=\"Greens\", annot=True, linewidth=0, annot_kws={\"size\":12}, fmt='.2f')\n",
    "plt.savefig(f\"{OUTPATH}{PREFIX}{FIG3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00ff0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:04.203795Z",
     "start_time": "2021-05-15T05:17:04.172879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Reduction -  Variance Inflation Factor [VIF]\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51959d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:04.315540Z",
     "start_time": "2021-05-15T05:17:04.205791Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"------ Variance Inflation Factor ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12bcb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:04.440578Z",
     "start_time": "2021-05-15T05:17:04.317492Z"
    }
   },
   "outputs": [],
   "source": [
    "vif_data.head(100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4b8ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:04.710079Z",
     "start_time": "2021-05-15T05:17:04.444569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Reduction - Principal Component Analysis [PCA]\n",
    "\n",
    "if n_target == 0:\n",
    "    X = df.copy()\n",
    "else:\n",
    "    X = df.drop(columns=targlst)\n",
    "    y = df.filter(targlst, axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Principal Component Analyses\n",
    "\n",
    "sklpca = SKLPCA(n_components=0.95, svd_solver='full')\n",
    "sklpca.fit(X_scaled)\n",
    "X_transform = sklpca.transform(X_scaled)\n",
    "\n",
    "pricom = pd.DataFrame(sklpca.components_.round(3)) # Principal Components\n",
    "pricomvar = pd.DataFrame(sklpca.explained_variance_ratio_.round(3))\n",
    "\n",
    "n_pca_comp = sklpca.n_components_\n",
    "print(\"No. of Components Explaining 95% Variance:\", n_pca_comp)\n",
    "\n",
    "# Identifying Top Features of  PCA using pca module\n",
    "\n",
    "model = pca(n_components=0.95, normalize=True, random_state=RND_STATE)\n",
    "out = model.fit_transform(X)\n",
    "pcatopfeat = out['topfeat'].round(3)\n",
    "\n",
    "# Identifying Top Features of  PCA using pca module\n",
    "\n",
    "model = pca(n_components=0.95, normalize=True, random_state=RND_STATE)\n",
    "out = model.fit_transform(X)\n",
    "pcatopfeat = out['topfeat'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d60477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:04.725084Z",
     "start_time": "2021-05-15T05:17:04.713072Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"------ Top Principal Component ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642d1cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:05.138434Z",
     "start_time": "2021-05-15T05:17:04.727035Z"
    }
   },
   "outputs": [],
   "source": [
    "FIG4 = r\"Fig_04_PCA_Model_Plot\"\n",
    "fig, ax = model.plot()\n",
    "ax.figure.savefig(f\"{OUTPATH}{PREFIX}{FIG4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccfbee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:05.592221Z",
     "start_time": "2021-05-15T05:17:05.139389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Importance - Decision Tree Classifier\n",
    "\n",
    "FIG44 = r\"Fig_44_Feature_Importance\"\n",
    "\n",
    "if n_target != 0:\n",
    "    X = df.drop(columns=targlst)\n",
    "    y = df.drop(columns=featlst)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TESTSIZE,\n",
    "                                                        random_state=RND_STATE)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    MLM_DTR = DecisionTreeClassifier(max_depth=5, random_state=RND_STATE)\n",
    "    MLM_DTR.fit(X_train, y_train)\n",
    "    feat_imp = MLM_DTR.feature_importances_.round(3)\n",
    "    colhead = X.columns.tolist()\n",
    "    featimp = pd.DataFrame(np.column_stack([colhead, feat_imp]), columns=['Features',\n",
    "                                                                          'Coefficients'])\n",
    "    featimp = featimp.sort_values('Coefficients', ascending=False)\n",
    "else:\n",
    "    featimptemp = {'Features':[np.nan], 'Coefficients':[np.nan],\n",
    "                   'Remarks':['Unsupervised Learning']}\n",
    "    featimp = pd.DataFrame(featimptemp, columns=['Features',\n",
    "                                                 'Coefficients', 'Remarks'])\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.yticks(range(0, len(featlst)), featlst)\n",
    "plt.barh(range(0, len(featlst)), MLM_DTR.feature_importances_, color='red', align='center')\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title(\"Feature Importance based on Decision Tree Classifier:\", fontsize=16)\n",
    "plt.savefig(f\"{OUTPATH}{PREFIX}{FIG44}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1688bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:28.070547Z",
     "start_time": "2021-05-15T05:17:05.593173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter Plot of Top Features of Importance from DTR\n",
    "\n",
    "FIG5 = r\"Fig_05_Scatter_Plot\"\n",
    "\n",
    "temp = featimp[\"Coefficients\"].to_numpy()\n",
    "\n",
    "cumsum = 0\n",
    "for i in range(0, len(temp), 1):\n",
    "    cumsum = cumsum + float(temp[i])\n",
    "    if cumsum >= 0.95:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "n_crit_feat = i\n",
    "\n",
    "DTR_featlst = featimp['Features'].to_list()\n",
    "topfeat = []\n",
    "for i in range(0, n_crit_feat+1, 1):\n",
    "    topfeat.append(DTR_featlst[i])\n",
    "print(\"Top Features:\", topfeat, end='\\n')\n",
    "\n",
    "topfeat.extend(targlst) # Adding target variables to topfeatures\n",
    "\n",
    "df_scatter = df.filter(topfeat, axis=1)\n",
    "grid1 = sns.pairplot(df_scatter, hue='Class_att')\n",
    "grid1.map(plt.scatter)\n",
    "grid1.map_diag(sns.kdeplot)\n",
    "grid1.add_legend()\n",
    "grid1.fig.suptitle(\"Features Explaining >= 95% Variance\", y=1.01)\n",
    "grid1.savefig(f\"{OUTPATH}{PREFIX}{FIG5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e7a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:17:28.922163Z",
     "start_time": "2021-05-15T05:17:28.072542Z"
    }
   },
   "outputs": [],
   "source": [
    "# EDA Report Out\n",
    "\n",
    "# Output to Excel\n",
    "\n",
    "SUMMARY = r\"00_Results_Summary.xlsx\"\n",
    "\n",
    "writer = pd.ExcelWriter(f\"{OUTPATH}{PREFIX}{SUMMARY}\", engine='xlsxwriter', options={'strings_to_numbers': True})\n",
    "DF_INFO.to_excel(writer, sheet_name='Info')\n",
    "desc_stat.to_excel(writer, sheet_name='Stats')\n",
    "vif_data.to_excel(writer, sheet_name='VIF')\n",
    "pricomvar.to_excel(writer, sheet_name='PCA_VAR')\n",
    "pricom.to_excel(writer, sheet_name='PCA_Components')\n",
    "pcatopfeat.to_excel(writer, sheet_name='PCA_Top_Features')\n",
    "featimp.to_excel(writer, sheet_name='DTR-Features')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075c7aa",
   "metadata": {},
   "source": [
    "### Conclusions & Recommendations\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "    1. Encoding: Normal = 0 | Abnormal (Patient) = 1\n",
    "    2. No missing values. No imputing is needed.\n",
    "    3. Normal : Anbormal :: 100 : 210.\n",
    "    4. Features have a mix of negative and positive values.\n",
    "    5. Features do not follow normal distribution strictly.\n",
    "    6. Few outliers exist.\n",
    "    7. Fair degree of linear separability exists.\n",
    "    8. Pelvic radius inversely related to Class_att.\n",
    "    9. Pelvic incidence has high correlation. A closer look shows that:\n",
    "        - pelvic_incidence = pelvic_tilt + sacral_slope\n",
    "    10. Needless to say, VIF is quiet high for some features indicating very high degree of multi-colliniarity.\n",
    "    11. 10 / 12 components are needed to explain 95% variance.\n",
    "    12. Top features explaining 95% variance in output based on Decision Tree:\n",
    "        ['degree_spondylolisthesis', 'sacral_slope', 'pelvic_radius', 'cervical_tilt', 'pelvic_tilt', 'sacrum_angle',\n",
    "        'pelvic_slope', 'pelvic_incidence']\n",
    "\n",
    "Recommendations:\n",
    "    \n",
    "    1. Remove pelvic incidence from model developement.\n",
    "    2. StandardScaler might be better than MinMaxScaler.\n",
    "    3. If desired accuracy is not achieved with the full dataset, it makes sense to go for downsampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136ec7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T05:41:20.333889Z",
     "start_time": "2021-05-15T05:41:16.382954Z"
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --output-dir=\"C:\\DSML_Case_Studies\\01_Classification\\00_Final_Reports\" EDA_FE_CLF_Dataset_Back_Pain.ipynb --to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897868e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
